"""
Brain - è‰ç¨¿ç”Ÿæˆå™¨
æ•´åˆ LLM Routing æ„åœ–åˆ†é¡èˆ‡ AI API ç”Ÿæˆå›è¦†è‰ç¨¿
æ”¯æ´æ¨¡å‹åˆ†æµï¼šç°¡å–®ä»»å‹™ç”¨ä¾¿å®œæ¨¡å‹ï¼Œè¤‡é›œä»»å‹™ç”¨é«˜ç´šæ¨¡å‹
æ”¯æ´å°è©±ä¸Šä¸‹æ–‡ï¼šå–å¾—åŒä¸€å®¢æˆ¶çš„æ­·å²å°è©±è¨˜éŒ„
"""
from typing import Dict, Optional, List
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, desc
from db.models import Message, Draft, Response, APIUsage
from services.claude_client import get_claude_client
from brain.router import get_intent_router
from api.routes.usage import calculate_cost
from config import settings


class DraftGenerator:
    """è‰ç¨¿ç”Ÿæˆå™¨ - æ”¯æ´ LLM Routing å’Œå°è©±ä¸Šä¸‹æ–‡"""

    def __init__(self):
        """åˆå§‹åŒ–è‰ç¨¿ç”Ÿæˆå™¨"""
        self.claude_client = get_claude_client()
        self.intent_router = get_intent_router()

    async def get_conversation_history(
        self,
        db: AsyncSession,
        sender_id: str,
        current_message_id: int
    ) -> str:
        """
        å–å¾—åŒä¸€å®¢æˆ¶çš„å°è©±æ­·å²

        Args:
            db: è³‡æ–™åº«é€£ç·š
            sender_id: ç™¼é€è€… IDï¼ˆç”¨ä¾†è­˜åˆ¥åŒä¸€å®¢æˆ¶ï¼‰
            current_message_id: ç•¶å‰è¨Šæ¯ IDï¼ˆæ’é™¤æ­¤è¨Šæ¯ï¼‰

        Returns:
            æ ¼å¼åŒ–çš„å°è©±æ­·å²å­—ä¸²
        """
        limit = settings.CONVERSATION_HISTORY_LIMIT

        # å–å¾—æ­¤å®¢æˆ¶æœ€è¿‘çš„è¨Šæ¯ï¼ˆä¸åŒ…å«ç•¶å‰è¨Šæ¯ï¼‰
        result = await db.execute(
            select(Message)
            .where(Message.sender_id == sender_id)
            .where(Message.id != current_message_id)
            .order_by(desc(Message.created_at))
            .limit(limit)
        )
        recent_messages = result.scalars().all()

        if not recent_messages:
            return ""

        # åè½‰é †åºï¼Œè®“æœ€èˆŠçš„åœ¨å‰é¢
        recent_messages = list(reversed(recent_messages))

        # å»ºç«‹å°è©±æ­·å²æ ¼å¼
        history_parts = ["## å°è©±æ­·å²ï¼ˆæœ€è¿‘ {} å‰‡ï¼‰\n".format(len(recent_messages))]

        for msg in recent_messages:
            # å–å¾—æ­¤è¨Šæ¯çš„å›è¦†ï¼ˆå¦‚æœæœ‰ï¼‰
            response_result = await db.execute(
                select(Response)
                .where(Response.message_id == msg.id)
                .order_by(desc(Response.sent_at))
                .limit(1)
            )
            response = response_result.scalar_one_or_none()

            # æ ¼å¼åŒ–æ™‚é–“
            time_str = msg.created_at.strftime("%m/%d %H:%M") if msg.created_at else ""

            # åŠ å…¥å®¢æˆ¶è¨Šæ¯
            history_parts.append(f"**[{time_str}] å®¢æˆ¶ï¼š**\n{msg.content}\n")

            # å¦‚æœæœ‰å›è¦†ï¼ŒåŠ å…¥å›è¦†å…§å®¹
            if response and response.final_content:
                history_parts.append(f"**[å›è¦†] Hour Jungleï¼š**\n{response.final_content}\n")

        history_parts.append("\n---\n\n")
        return "\n".join(history_parts)

    async def generate(
        self,
        db: AsyncSession,
        message_id: int,
        content: str,
        sender_name: str,
        source: str,
        sender_id: str = ""
    ) -> Draft:
        """
        ç”Ÿæˆè‰ç¨¿ - æ”¯æ´ LLM Routing æ¨¡å‹åˆ†æµ + å°è©±ä¸Šä¸‹æ–‡

        æµç¨‹ï¼š
        1. å–å¾—å°è©±æ­·å²ï¼ˆåŒä¸€å®¢æˆ¶çš„æœ€è¿‘ N å‰‡å°è©±ï¼‰
        2. å…ˆç”¨ Smart Model åˆ¤æ–·ä»»å‹™è¤‡é›œåº¦
        3. æ ¹æ“šè¤‡é›œåº¦é¸æ“‡æ¨¡å‹
        4. åŸ·è¡Œè‰ç¨¿ç”Ÿæˆï¼ˆåŒ…å«å°è©±ä¸Šä¸‹æ–‡ï¼‰
        5. è¨˜éŒ„ API ç”¨é‡
        """
        try:
            # === ç¬¬é›¶æ­¥ï¼šå–å¾—å°è©±æ­·å² ===
            conversation_history = ""
            if sender_id:
                conversation_history = await self.get_conversation_history(
                    db=db,
                    sender_id=sender_id,
                    current_message_id=message_id
                )
                if conversation_history:
                    print(f"ğŸ“œ è¼‰å…¥å°è©±æ­·å² (sender_id: {sender_id[:20]}...)")

            # === ç¬¬ä¸€æ­¥ï¼šLLM Routing åˆ†æµåˆ¤æ–· ===
            routing_result = await self.claude_client.route_task(content)
            complexity = routing_result.get("complexity", "COMPLEX")
            routing_reason = routing_result.get("reason", "")
            suggested_intent = routing_result.get("suggested_intent", "å…¶ä»–")

            # è¨˜éŒ„ Router çš„ API ç”¨é‡
            router_usage = routing_result.get("_usage")
            if router_usage and router_usage.get("input_tokens", 0) > 0:
                router_api_usage = APIUsage(
                    provider="openrouter" if settings.AI_PROVIDER == "openrouter" else "anthropic",
                    model=router_usage.get("model", "unknown"),
                    operation="routing",
                    input_tokens=router_usage.get("input_tokens", 0),
                    output_tokens=router_usage.get("output_tokens", 0),
                    total_tokens=router_usage.get("input_tokens", 0) + router_usage.get("output_tokens", 0),
                    estimated_cost=calculate_cost(
                        router_usage.get("model", "default"),
                        router_usage.get("input_tokens", 0),
                        router_usage.get("output_tokens", 0)
                    ),
                    success=True
                )
                db.add(router_api_usage)

            # === ç¬¬äºŒæ­¥ï¼šæ±ºå®šä½¿ç”¨çš„æ¨¡å‹ ===
            if complexity == "SIMPLE":
                target_model = settings.MODEL_FAST
                strategy_prefix = f"âš¡ å¿«é€Ÿæ¨¡å¼ ({routing_reason})"
                print(f"ğŸ¤– [SIMPLE] ä½¿ç”¨ Fast Model: {target_model}")
            else:
                target_model = settings.MODEL_SMART
                strategy_prefix = f"ğŸ§  æ·±åº¦æ¨¡å¼ ({routing_reason})"
                print(f"ğŸ¤– [COMPLEX] ä½¿ç”¨ Smart Model: {target_model}")

            # === ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆè‰ç¨¿ï¼ˆå«å°è©±ä¸Šä¸‹æ–‡ï¼‰===
            draft_result = await self.claude_client.generate_draft(
                message=content,
                sender_name=sender_name,
                source=source,
                context={"intent": suggested_intent, "routing": routing_result},
                model=target_model if settings.AI_PROVIDER == "openrouter" else None,
                conversation_history=conversation_history
            )

            # === ç¬¬å››æ­¥ï¼šè¨˜éŒ„ç”Ÿæˆçš„ API ç”¨é‡ ===
            usage_info = draft_result.pop("_usage", None)
            if usage_info:
                api_usage = APIUsage(
                    provider="openrouter" if settings.AI_PROVIDER == "openrouter" else "anthropic",
                    model=usage_info.get("model", "unknown"),
                    operation="draft_generation",
                    input_tokens=usage_info.get("input_tokens", 0),
                    output_tokens=usage_info.get("output_tokens", 0),
                    total_tokens=usage_info.get("input_tokens", 0) + usage_info.get("output_tokens", 0),
                    estimated_cost=calculate_cost(
                        usage_info.get("model", "default"),
                        usage_info.get("input_tokens", 0),
                        usage_info.get("output_tokens", 0)
                    ),
                    success=True
                )
                db.add(api_usage)

            # === ç¬¬äº”æ­¥ï¼šçµ„åˆç­–ç•¥èªªæ˜ä¸¦å„²å­˜ ===
            ai_strategy = draft_result.get("strategy", "")
            final_strategy = f"{strategy_prefix}\n{ai_strategy}"

            draft = Draft(
                message_id=message_id,
                content=draft_result.get("draft", ""),
                strategy=final_strategy,
                intent=draft_result.get("intent", suggested_intent),
                is_selected=False
            )

            db.add(draft)
            await db.commit()
            await db.refresh(draft)

            # æ›´æ–° Message ç‹€æ…‹ç‚º drafted
            result = await db.execute(
                select(Message).where(Message.id == message_id)
            )
            message = result.scalar_one_or_none()
            if message:
                message.status = "drafted"
                await db.commit()

            print(f"âœ… è‰ç¨¿ç”Ÿæˆå®Œæˆ (Message ID: {message_id}, æ¨¡å¼: {complexity})")
            return draft

        except Exception as e:
            # è¨˜éŒ„å¤±æ•—çš„ API èª¿ç”¨
            try:
                api_usage = APIUsage(
                    provider="openrouter" if settings.AI_PROVIDER == "openrouter" else "anthropic",
                    model=settings.MODEL_SMART,
                    operation="draft_generation",
                    input_tokens=0,
                    output_tokens=0,
                    total_tokens=0,
                    estimated_cost=0,
                    success=False,
                    error_message=str(e)
                )
                db.add(api_usage)
                await db.commit()
            except:
                pass
            await db.rollback()
            print(f"âŒ è‰ç¨¿ç”Ÿæˆå¤±æ•—: {str(e)}")
            raise Exception(f"è‰ç¨¿ç”Ÿæˆå¤±æ•—: {str(e)}")

    async def regenerate(
        self,
        db: AsyncSession,
        message_id: int
    ) -> Draft:
        """
        é‡æ–°ç”Ÿæˆè‰ç¨¿
        """
        # å–å¾—åŸå§‹è¨Šæ¯
        result = await db.execute(
            select(Message).where(Message.id == message_id)
        )
        message = result.scalar_one_or_none()

        if not message:
            raise ValueError(f"æ‰¾ä¸åˆ°è¨Šæ¯ ID: {message_id}")

        # ç”Ÿæˆæ–°è‰ç¨¿
        return await self.generate(
            db=db,
            message_id=message_id,
            content=message.content,
            sender_name=message.sender_name,
            source=message.source
        )


# å…¨åŸŸè‰ç¨¿ç”Ÿæˆå™¨å¯¦ä¾‹
_draft_generator: Optional[DraftGenerator] = None


def get_draft_generator() -> DraftGenerator:
    """å–å¾—è‰ç¨¿ç”Ÿæˆå™¨å–®ä¾‹"""
    global _draft_generator
    if _draft_generator is None:
        _draft_generator = DraftGenerator()
    return _draft_generator
