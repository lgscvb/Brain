"""
Brain - è‰ç¨¿ç”Ÿæˆå™¨
æ•´åˆ LLM Routing æ„åœ–åˆ†é¡èˆ‡ AI API ç”Ÿæˆå›è¦†è‰ç¨¿

ã€æ ¸å¿ƒåŠŸèƒ½ã€‘
1. LLM Routingï¼šç°¡å–®ä»»å‹™ç”¨ä¾¿å®œæ¨¡å‹ï¼Œè¤‡é›œä»»å‹™ç”¨é«˜ç´šæ¨¡å‹
2. å°è©±ä¸Šä¸‹æ–‡ï¼šå–å¾—åŒä¸€å®¢æˆ¶çš„æ­·å²å°è©±è¨˜éŒ„
3. RAGï¼šå‹•æ…‹æª¢ç´¢ç›¸é—œçŸ¥è­˜æ³¨å…¥ Prompt
4. Jungle CRM æ•´åˆï¼šæŸ¥è©¢å®¢æˆ¶è³‡æ–™ã€åˆç´„ç‹€æ…‹

ã€æµç¨‹ã€‘
å®¢æˆ¶è¨Šæ¯ â†’ Routing åˆ¤æ–· â†’ é¸æ“‡æ¨¡å‹ â†’ RAG æª¢ç´¢ â†’ CRM æŸ¥è©¢ â†’ ç”Ÿæˆè‰ç¨¿
"""
from typing import Dict, Optional, List
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, desc
from db.models import Message, Draft, Response, APIUsage, Attachment
from services.claude_client import get_claude_client
from services.rag_service import get_rag_service
from services.crm_client import get_crm_client
from api.routes.usage import calculate_cost
from config import settings

# å‹åˆ¥å®šç¾©çµ±ä¸€å¾ type_defs å°å…¥
from type_defs import UsageInfo, RoutingResult, DraftResult, Complexity


class DraftGenerator:
    """è‰ç¨¿ç”Ÿæˆå™¨ - æ”¯æ´ LLM Routingã€å°è©±ä¸Šä¸‹æ–‡ã€RAG å’Œ Jungle CRM æ•´åˆ"""

    def __init__(self):
        """åˆå§‹åŒ–è‰ç¨¿ç”Ÿæˆå™¨"""
        self.claude_client = get_claude_client()
        self.rag_service = get_rag_service()
        self.crm_client = get_crm_client()

    async def get_conversation_history(
        self,
        db: AsyncSession,
        sender_id: str,
        current_message_id: int
    ) -> str:
        """
        å–å¾—åŒä¸€å®¢æˆ¶çš„å°è©±æ­·å²

        Args:
            db: è³‡æ–™åº«é€£ç·š
            sender_id: ç™¼é€è€… IDï¼ˆç”¨ä¾†è­˜åˆ¥åŒä¸€å®¢æˆ¶ï¼‰
            current_message_id: ç•¶å‰è¨Šæ¯ IDï¼ˆæ’é™¤æ­¤è¨Šæ¯ï¼‰

        Returns:
            æ ¼å¼åŒ–çš„å°è©±æ­·å²å­—ä¸²
        """
        limit = settings.CONVERSATION_HISTORY_LIMIT

        # å–å¾—æ­¤å®¢æˆ¶æœ€è¿‘çš„è¨Šæ¯ï¼ˆä¸åŒ…å«ç•¶å‰è¨Šæ¯ï¼‰
        result = await db.execute(
            select(Message)
            .where(Message.sender_id == sender_id)
            .where(Message.id != current_message_id)
            .order_by(desc(Message.created_at))
            .limit(limit)
        )
        recent_messages = result.scalars().all()

        if not recent_messages:
            return ""

        # åè½‰é †åºï¼Œè®“æœ€èˆŠçš„åœ¨å‰é¢
        recent_messages = list(reversed(recent_messages))

        # å»ºç«‹å°è©±æ­·å²æ ¼å¼
        history_parts = ["## å°è©±æ­·å²ï¼ˆæœ€è¿‘ {} å‰‡ï¼‰\n".format(len(recent_messages))]

        for msg in recent_messages:
            # å–å¾—æ­¤è¨Šæ¯çš„å›è¦†ï¼ˆå¦‚æœæœ‰ï¼‰
            response_result = await db.execute(
                select(Response)
                .where(Response.message_id == msg.id)
                .order_by(desc(Response.sent_at))
                .limit(1)
            )
            response = response_result.scalar_one_or_none()

            # æ ¼å¼åŒ–æ™‚é–“
            time_str = msg.created_at.strftime("%m/%d %H:%M") if msg.created_at else ""

            # åŠ å…¥å®¢æˆ¶è¨Šæ¯ï¼Œä¸¦æ¨™ç¤ºå›è¦†ç‹€æ…‹
            if response and response.final_content:
                # å·²å›è¦†çš„è¨Šæ¯
                history_parts.append(f"**[{time_str}] å®¢æˆ¶ï¼š**\n{msg.content}\n")
                history_parts.append(f"**[âœ“ å·²å›è¦†] Hour Jungleï¼š**\n{response.final_content}\n")
            else:
                # å°šæœªå›è¦†çš„è¨Šæ¯ - ç”¨é†’ç›®æ¨™è¨˜æé†’ LLM
                history_parts.append(f"**[{time_str}] å®¢æˆ¶ï¼š**\n{msg.content}\n")
                history_parts.append(f"**[âš ï¸ æ­¤è¨Šæ¯å°šæœªå›è¦†]**\n")

        history_parts.append("\n---\n\n")
        return "\n".join(history_parts)

    async def get_media_context(
        self,
        db: AsyncSession,
        sender_id: str,
        current_message_id: int
    ) -> str:
        """
        å–å¾—æ­¤å°è©±ä¸­çš„åª’é«”é™„ä»¶ä¸Šä¸‹æ–‡ï¼ˆåœ–ç‰‡ OCRã€PDF æ–‡å­—ç­‰ï¼‰

        é€™å€‹ä¸Šä¸‹æ–‡è®“ LLM çŸ¥é“å®¢æˆ¶å‚³é€äº†å“ªäº›æª”æ¡ˆå’Œåœ–ç‰‡ï¼Œ
        ä»¥åŠé€™äº›åª’é«”ä¸­åŒ…å«çš„æ–‡å­—å…§å®¹ã€‚

        Args:
            db: è³‡æ–™åº«é€£ç·š
            sender_id: ç™¼é€è€… ID
            current_message_id: ç•¶å‰è¨Šæ¯ ID

        Returns:
            æ ¼å¼åŒ–çš„åª’é«”ä¸Šä¸‹æ–‡å­—ä¸²
        """
        # æŸ¥è©¢æ­¤å®¢æˆ¶æœ€è¿‘çš„åª’é«”é™„ä»¶ï¼ˆé™åˆ¶ 5 å€‹ï¼Œåªå– OCR å®Œæˆçš„ï¼‰
        result = await db.execute(
            select(Attachment)
            .join(Message)
            .where(Message.sender_id == sender_id)
            .where(Attachment.ocr_status == "completed")
            .where(Attachment.ocr_text.isnot(None))
            .where(Attachment.ocr_text != "")
            .order_by(desc(Attachment.created_at))
            .limit(5)
        )
        attachments = result.scalars().all()

        if not attachments:
            return ""

        # åè½‰é †åºï¼Œè®“æœ€èˆŠçš„åœ¨å‰é¢
        attachments = list(reversed(attachments))

        parts = ["## å®¢æˆ¶å‚³é€çš„åª’é«”æª”æ¡ˆ\n"]

        for att in attachments:
            time_str = att.created_at.strftime("%m/%d %H:%M") if att.created_at else ""

            if att.media_type == "image":
                # åœ–ç‰‡ OCR çµæœ
                ocr_preview = att.ocr_text[:500] + "..." if len(att.ocr_text) > 500 else att.ocr_text
                parts.append(f"**[{time_str}] åœ–ç‰‡å…§å®¹ï¼š**\n{ocr_preview}\n")

            elif att.media_type == "pdf":
                # PDF æ–‡å­—å…§å®¹
                ocr_preview = att.ocr_text[:800] + "..." if len(att.ocr_text) > 800 else att.ocr_text
                file_info = f" ({att.file_name})" if att.file_name else ""
                parts.append(f"**[{time_str}] PDF æ–‡ä»¶{file_info}ï¼š**\n{ocr_preview}\n")

            elif att.media_type == "file":
                # ä¸€èˆ¬æª”æ¡ˆï¼ˆé€šå¸¸æ²’æœ‰ OCRï¼‰
                if att.ocr_text:
                    ocr_preview = att.ocr_text[:500] + "..." if len(att.ocr_text) > 500 else att.ocr_text
                    parts.append(f"**[{time_str}] æª”æ¡ˆ ({att.file_name})ï¼š**\n{ocr_preview}\n")

        parts.append("\n---\n\n")
        return "\n".join(parts)

    async def generate(
        self,
        db: AsyncSession,
        message_id: int,
        content: str,
        sender_name: str,
        source: str,
        sender_id: str = ""
    ) -> Draft:
        """
        ç”Ÿæˆè‰ç¨¿ - æ”¯æ´ LLM Routing æ¨¡å‹åˆ†æµ + å°è©±ä¸Šä¸‹æ–‡

        æµç¨‹ï¼š
        1. å–å¾—å°è©±æ­·å²ï¼ˆåŒä¸€å®¢æˆ¶çš„æœ€è¿‘ N å‰‡å°è©±ï¼‰
        2. å…ˆç”¨ Smart Model åˆ¤æ–·ä»»å‹™è¤‡é›œåº¦
        3. æ ¹æ“šè¤‡é›œåº¦é¸æ“‡æ¨¡å‹
        4. åŸ·è¡Œè‰ç¨¿ç”Ÿæˆï¼ˆåŒ…å«å°è©±ä¸Šä¸‹æ–‡ï¼‰
        5. è¨˜éŒ„ API ç”¨é‡
        """
        try:
            # === ç¬¬é›¶æ­¥ï¼šå–å¾—å°è©±æ­·å² ===
            conversation_history = ""
            if sender_id:
                conversation_history = await self.get_conversation_history(
                    db=db,
                    sender_id=sender_id,
                    current_message_id=message_id
                )
                if conversation_history:
                    print(f"ğŸ“œ è¼‰å…¥å°è©±æ­·å² (sender_id: {sender_id[:20]}...)")

            # === ç¬¬é›¶.äº”æ­¥ï¼šå–å¾—åª’é«”ä¸Šä¸‹æ–‡ï¼ˆåœ–ç‰‡ OCRã€PDF ç­‰ï¼‰===
            media_context = ""
            if sender_id:
                media_context = await self.get_media_context(
                    db=db,
                    sender_id=sender_id,
                    current_message_id=message_id
                )
                if media_context:
                    print(f"ğŸ–¼ï¸ è¼‰å…¥åª’é«”ä¸Šä¸‹æ–‡ (sender_id: {sender_id[:20]}...)")

            # === ç¬¬ä¸€æ­¥ï¼šLLM Routing åˆ†æµåˆ¤æ–· ===
            routing_result = await self.claude_client.route_task(content)
            complexity = routing_result.get("complexity", "COMPLEX")
            routing_reason = routing_result.get("reason", "")
            suggested_intent = routing_result.get("suggested_intent", "å…¶ä»–")

            # è¨˜éŒ„ Router çš„ API ç”¨é‡
            router_usage = routing_result.get("_usage")
            if router_usage and router_usage.get("input_tokens", 0) > 0:
                router_api_usage = APIUsage(
                    provider="openrouter" if settings.AI_PROVIDER == "openrouter" else "anthropic",
                    model=router_usage.get("model", "unknown"),
                    operation="routing",
                    input_tokens=router_usage.get("input_tokens", 0),
                    output_tokens=router_usage.get("output_tokens", 0),
                    total_tokens=router_usage.get("input_tokens", 0) + router_usage.get("output_tokens", 0),
                    estimated_cost=calculate_cost(
                        router_usage.get("model", "default"),
                        router_usage.get("input_tokens", 0),
                        router_usage.get("output_tokens", 0)
                    ),
                    success=True
                )
                db.add(router_api_usage)

            # === ç¬¬äºŒæ­¥ï¼šæ±ºå®šä½¿ç”¨çš„æ¨¡å‹ ===
            if complexity == "SIMPLE":
                target_model = settings.MODEL_FAST
                strategy_prefix = f"âš¡ å¿«é€Ÿæ¨¡å¼ ({routing_reason})"
                print(f"ğŸ¤– [SIMPLE] ä½¿ç”¨ Fast Model: {target_model}")
            else:
                target_model = settings.MODEL_SMART
                strategy_prefix = f"ğŸ§  æ·±åº¦æ¨¡å¼ ({routing_reason})"
                print(f"ğŸ¤– [COMPLEX] ä½¿ç”¨ Smart Model: {target_model}")

            # === ç¬¬äºŒ.äº”æ­¥ï¼šRAG çŸ¥è­˜æª¢ç´¢ ===
            rag_context = ""
            try:
                rag_context = await self.rag_service.get_relevant_context(
                    db=db,
                    message=content,
                    top_k=5
                )
                if rag_context:
                    print(f"ğŸ“š RAG æª¢ç´¢åˆ°ç›¸é—œçŸ¥è­˜")
            except Exception as e:
                print(f"âš ï¸ RAG æª¢ç´¢å¤±æ•—: {e}")

            # === ç¬¬äºŒ.ä¸ƒæ­¥ï¼šæŸ¥è©¢ Jungle CRM å®¢æˆ¶è³‡æ–™ ===
            customer_context = ""
            if sender_id and settings.ENABLE_JUNGLE_INTEGRATION:
                try:
                    customer_data = await self.crm_client.get_customer_by_line_id(sender_id)
                    if customer_data:
                        customer_context = self.crm_client.format_customer_context(customer_data)
                        print(f"ğŸ‘¤ è¼‰å…¥ CRM å®¢æˆ¶è³‡æ–™: {customer_data.get('name', 'æœªçŸ¥')}")
                    else:
                        print(f"â„¹ï¸ CRM ä¸­ç„¡æ­¤å®¢æˆ¶è¨˜éŒ„ (sender_id: {sender_id[:20]}...)")
                except Exception as e:
                    print(f"âš ï¸ æŸ¥è©¢ CRM å®¢æˆ¶è³‡æ–™å¤±æ•—: {e}")

            # === ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆè‰ç¨¿ï¼ˆå«å°è©±ä¸Šä¸‹æ–‡ + åª’é«”ä¸Šä¸‹æ–‡ + RAG çŸ¥è­˜ + å®¢æˆ¶è³‡æ–™ï¼‰===
            # åˆä½µåª’é«”ä¸Šä¸‹æ–‡å’Œå°è©±æ­·å²ï¼ˆåª’é«”åœ¨å‰ï¼Œå°è©±åœ¨å¾Œï¼‰
            combined_history = ""
            if media_context:
                combined_history += media_context + "\n"
            if conversation_history:
                combined_history += conversation_history

            draft_result = await self.claude_client.generate_draft(
                message=content,
                sender_name=sender_name,
                source=source,
                context={"intent": suggested_intent, "routing": routing_result},
                model=target_model if settings.AI_PROVIDER == "openrouter" else None,
                conversation_history=combined_history,
                rag_context=rag_context,
                customer_context=customer_context
            )

            # === ç¬¬ä¸‰.äº”æ­¥ï¼šæœƒè­°å®¤é ç´„æ„åœ–è™•ç†ï¼ˆæš«æ™‚åœç”¨ï¼‰===
            # ç›®å‰æœƒè­°å®¤ç›¸é—œè©¢å•ç”±å®¢æœäººå“¡è™•ç†ï¼Œä¸è‡ªå‹•è½‰ç™¼ MCP
            # å¾…ç³»çµ±ç©©å®šå¾Œå†å•Ÿç”¨
            # result_intent = draft_result.get("intent", "")
            # if result_intent == "é ç´„æœƒè­°å®¤":
            #     ... (æš«æ™‚åœç”¨)

            # === ç¬¬å››æ­¥ï¼šè¨˜éŒ„ç”Ÿæˆçš„ API ç”¨é‡ ===
            usage_info = draft_result.pop("_usage", None)
            if usage_info:
                api_usage = APIUsage(
                    provider="openrouter" if settings.AI_PROVIDER == "openrouter" else "anthropic",
                    model=usage_info.get("model", "unknown"),
                    operation="draft_generation",
                    input_tokens=usage_info.get("input_tokens", 0),
                    output_tokens=usage_info.get("output_tokens", 0),
                    total_tokens=usage_info.get("input_tokens", 0) + usage_info.get("output_tokens", 0),
                    estimated_cost=calculate_cost(
                        usage_info.get("model", "default"),
                        usage_info.get("input_tokens", 0),
                        usage_info.get("output_tokens", 0)
                    ),
                    success=True
                )
                db.add(api_usage)

            # === ç¬¬äº”æ­¥ï¼šçµ„åˆç­–ç•¥èªªæ˜ä¸¦å„²å­˜ ===
            ai_strategy = draft_result.get("strategy", "")
            final_strategy = f"{strategy_prefix}\n{ai_strategy}"

            draft = Draft(
                message_id=message_id,
                content=draft_result.get("draft", ""),
                strategy=final_strategy,
                intent=draft_result.get("intent", suggested_intent),
                is_selected=False
            )

            db.add(draft)
            await db.commit()
            await db.refresh(draft)

            # æ›´æ–° Message ç‹€æ…‹ç‚º drafted
            result = await db.execute(
                select(Message).where(Message.id == message_id)
            )
            message = result.scalar_one_or_none()
            if message:
                message.status = "drafted"
                await db.commit()

            print(f"âœ… è‰ç¨¿ç”Ÿæˆå®Œæˆ (Message ID: {message_id}, æ¨¡å¼: {complexity})")
            return draft

        except Exception as e:
            # è¨˜éŒ„å¤±æ•—çš„ API èª¿ç”¨
            try:
                api_usage = APIUsage(
                    provider="openrouter" if settings.AI_PROVIDER == "openrouter" else "anthropic",
                    model=settings.MODEL_SMART,
                    operation="draft_generation",
                    input_tokens=0,
                    output_tokens=0,
                    total_tokens=0,
                    estimated_cost=0,
                    success=False,
                    error_message=str(e)
                )
                db.add(api_usage)
                await db.commit()
            except:
                pass
            await db.rollback()
            print(f"âŒ è‰ç¨¿ç”Ÿæˆå¤±æ•—: {str(e)}")
            raise Exception(f"è‰ç¨¿ç”Ÿæˆå¤±æ•—: {str(e)}")

    async def regenerate(
        self,
        db: AsyncSession,
        message_id: int
    ) -> Draft:
        """
        é‡æ–°ç”Ÿæˆè‰ç¨¿
        """
        # å–å¾—åŸå§‹è¨Šæ¯
        result = await db.execute(
            select(Message).where(Message.id == message_id)
        )
        message = result.scalar_one_or_none()

        if not message:
            raise ValueError(f"æ‰¾ä¸åˆ°è¨Šæ¯ ID: {message_id}")

        # ç”Ÿæˆæ–°è‰ç¨¿ï¼ˆåŒ…å« sender_id ä»¥å–å¾—å°è©±æ­·å²ï¼‰
        return await self.generate(
            db=db,
            message_id=message_id,
            content=message.content,
            sender_name=message.sender_name,
            source=message.source,
            sender_id=message.sender_id
        )

    async def generate_for_conversation(
        self,
        db: AsyncSession,
        sender_id: str
    ) -> Draft:
        """
        å°è©±ç´šåˆ¥è‰ç¨¿ç”Ÿæˆ - è®€å–æ‰€æœ‰æœªå›è¦†è¨Šæ¯ï¼Œç”Ÿæˆä¸€å€‹æ•´åˆå›è¦†

        Args:
            db: è³‡æ–™åº«é€£ç·š
            sender_id: å®¢æˆ¶ ID

        Returns:
            ç”Ÿæˆçš„è‰ç¨¿ï¼ˆé—œè¯åˆ°æœ€æ–°çš„è¨Šæ¯ï¼‰
        """
        # å–å¾—è©²å®¢æˆ¶æ‰€æœ‰æœªå›è¦†è¨Šæ¯ï¼ˆpending æˆ– draftedï¼‰
        result = await db.execute(
            select(Message)
            .where(Message.sender_id == sender_id)
            .where(Message.status.in_(["pending", "drafted"]))
            .where(Message.source.notin_(["line_bot", "system"]))  # æ’é™¤ bot å›è¦†
            .order_by(Message.created_at.asc())  # èˆŠçš„åœ¨å‰
        )
        pending_messages = result.scalars().all()

        if not pending_messages:
            raise ValueError("æ­¤å®¢æˆ¶æ²’æœ‰å¾…è™•ç†çš„è¨Šæ¯")

        # åˆä½µæ‰€æœ‰æœªå›è¦†è¨Šæ¯çš„å…§å®¹
        combined_content_parts = []
        for msg in pending_messages:
            time_str = msg.created_at.strftime("%m/%d %H:%M") if msg.created_at else ""
            combined_content_parts.append(f"[{time_str}] {msg.content}")

        combined_content = "\n\n".join(combined_content_parts)

        # å–å¾—æœ€æ–°è¨Šæ¯çš„åŸºæœ¬è³‡è¨Š
        latest_message = pending_messages[-1]

        print(f"ğŸ“¬ å°è©±ç´šåˆ¥è‰ç¨¿ç”Ÿæˆï¼šåˆä½µ {len(pending_messages)} å‰‡è¨Šæ¯")

        # ä½¿ç”¨æ¨™æº–ç”Ÿæˆæµç¨‹
        draft = await self.generate(
            db=db,
            message_id=latest_message.id,  # é—œè¯åˆ°æœ€æ–°è¨Šæ¯
            content=combined_content,
            sender_name=latest_message.sender_name,
            source=latest_message.source,
            sender_id=sender_id
        )

        # æ›´æ–°æ‰€æœ‰ç›¸é—œè¨Šæ¯çš„ç‹€æ…‹ç‚º drafted
        for msg in pending_messages:
            msg.status = "drafted"
        await db.commit()

        return draft


# å…¨åŸŸè‰ç¨¿ç”Ÿæˆå™¨å¯¦ä¾‹
_draft_generator: Optional[DraftGenerator] = None


def get_draft_generator() -> DraftGenerator:
    """å–å¾—è‰ç¨¿ç”Ÿæˆå™¨å–®ä¾‹"""
    global _draft_generator
    if _draft_generator is None:
        _draft_generator = DraftGenerator()
    return _draft_generator
